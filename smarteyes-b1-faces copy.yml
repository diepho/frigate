mqtt:
  host: 172.17.0.253
  port: 9003
  user: smarteyes-b1-faces
  password: qwrtqwrt@123
#  port: 9004
#  user: virtserver
#  password: qwrtqwrt
  topic_prefix: smarteyes-b1-faces-12.0
  client_id: smarteyes-b1-faces-12.0


# Optional: Detectors configuration. Defaults to a single CPU detector
detectors:
  # Required: name of the detector
  # cpu1:
    # Required: type of the detector
    # Valid values are 'edgetpu' (requires device property below) and 'cpu'.
    # type: cpu
    # Optional: device name as defined here: https://coral.ai/docs/edgetpu/multiple-edgetpu/#using-the-tensorflow-lite-python-api
#    device: usb
    # Optional: num_threads value passed to the tflite.Interpreter (default: shown below)
    # This value is only used for CPU types
  #  num_threads: 3
  tensorrt0:
    type: tensorrt
    device: 0 #This is the default, select the first GPU

# Optional: model modifications
# model:
#   # Optional: path to the model (default: automatic based on detector)
#   path: /edgetpu_model.tflite
#   # Optional: path to the labelmap (default: shown below)
#   labelmap_path: /labelmap.txt
#   # Required: Object detection model input width (default: shown below)
#   width: 320
#   # Required: Object detection model input height (default: shown below)
#   height: 320

model:
#  path: /trt-models/yolov7-tiny-416.trt
  path: /trt-models/yolov4-tiny-3l-416.trt
  input_tensor: nchw
  input_pixel_format: rgb
  width: 416
  height: 416

# Optional: logger verbosity settings
logger:
  # Optional: Default log verbosity (default: shown below)
  default: info
  # Optional: Component specific logger overrides
  logs:
    frigate.event: debug

# Optional: birdseye configuration
# NOTE: Can (enabled, mode) be overridden at the camera level
birdseye:
  # Optional: Enable birdseye view (default: shown below)
  enabled: True
  # Optional: Restream birdseye via RTSP (default: shown below)
  # NOTE: Enabling this will set birdseye to run 24/7 which may increase CPU usage somewhat.
  restream: True
  # Optional: Width of the output resolution (default: shown below)
  width: 1920
  # Optional: Height of the output resolution (default: shown below)
  height: 1080
  # Optional: Encoding quality of the mpeg1 feed (default: shown below)
  # 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
  quality: 8
  # Optional: Mode of the view. Available options are: objects, motion, and continuous
  #   objects - cameras are included if they have had a tracked object within the last 30 seconds
  #   motion - cameras are included if motion was detected in the last 30 seconds
  #   continuous - all cameras are included always
  mode: objects

# Optional: ffmpeg configuration
ffmpeg:
  # Optional: global ffmpeg args (default: shown below)
  global_args: -hide_banner -loglevel warning
  # Optional: global hwaccel args (default: shown below)
  # NOTE: See hardware acceleration docs for your specific device
  hwaccel_args: [] #preset-nvidia-h264
  # Optional: global input args (default: shown below)
  input_args: -avoid_negative_ts make_zero -fflags +genpts+discardcorrupt -rtsp_transport tcp -timeout 5000000 -use_wallclock_as_timestamps 1
  # Optional: global output args
  output_args:
    # Optional: output args for detect streams (default: shown below)
    detect: -f rawvideo -pix_fmt yuv420p
    # Optional: output args for record streams (default: shown below)
    record: -f segment -segment_time 10 -segment_format mp4 -reset_timestamps 1 -strftime 1 -c copy -an
    # Optional: output args for rtmp streams (default: shown below)
    rtmp: -c copy -f flv

# Optional: Detect configuration
# NOTE: Can be overridden at the camera level
detect:
  # Optional: width of the frame for the input with the detect role (default: shown below)
  width: 1920
  # Optional: height of the frame for the input with the detect role (default: shown below)
  height: 1080
  # Optional: desired fps for your camera for the input with the detect role (default: shown below)
  # NOTE: Recommended value of 5. Ideally, try and reduce your FPS on the camera.
  fps: 5
  # Optional: enables detection for the camera (default: True)
  # This value can be set via MQTT and will be updated in startup based on retained value
  enabled: True
  # Optional: Number of frames without a detection before frigate considers an object to be gone. (default: 5x the frame rate)
  max_disappeared: 25
  # Optional: Configuration for stationary object tracking
  stationary:
    # Optional: Frequency for confirming stationary objects (default: shown below)
    # When set to 0, object detection will not confirm stationary objects until movement is detected.
    # If set to 10, object detection will run to confirm the object still exists on every 10th frame.
    interval: 0
    # Optional: Number of frames without a position change for an object to be considered stationary (default: 10x the frame rate or 10s)
    threshold: 50
    # Optional: Define a maximum number of frames for tracking a stationary object (default: not set, track forever)
    # This can help with false positives for objects that should only be stationary for a limited amount of time.
    # It can also be used to disable stationary object tracking. For example, you may want to set a value for person, but leave
    # car at the default.
    # WARNING: Setting these values overrides default behavior and disables stationary object tracking.
    #          There are very few situations where you would want it disabled. It is NOT recommended to
    #          copy these values from the example config into your config unless you know they are needed.
    max_frames:
      # Optional: Default for all object types (default: not set, track forever)
      default: 3000
      # Optional: Object specific values
      objects:
        person: 1000
        face: 1000

# Optional: Object configuration
# NOTE: Can be overridden at the camera level
objects:
  # Optional: list of objects to track from labelmap.txt (default: shown below)
  track:
    - person
#    - bicycle
#    - car
#    - motorcycle
#    - bus

  # Optional: mask to prevent all object types from being detected in certain areas (default: no mask)
  # Checks based on the bottom center of the bounding box of the object.
  # NOTE: This mask is COMBINED with the object type specific mask below
  #mask: 0,0,1000,0,1000,200,0,200
  # Optional: filters to reduce false positives for specific object types
  filters:
    person:
      # Optional: minimum width*height of the bounding box for the detected object (default: 0)
      min_area: 5000
      # Optional: maximum width*height of the bounding box for the detected object (default: 24000000)
      max_area: 100000
      # Optional: minimum width/height of the bounding box for the detected object (default: 0)
      min_ratio: 0.5
      # Optional: maximum width/height of the bounding box for the detected object (default: 24000000)
      max_ratio: 2.0
      # Optional: minimum score for the object to initiate tracking (default: shown below)
      min_score: 0.5
      # Optional: minimum decimal percentage for tracked object's computed score to be considered a true positive (default: shown below)
      threshold: 0.7
      # Optional: mask to prevent this object type from being detected in certain areas (default: no mask)
      # Checks based on the bottom center of the bounding box of the object
      mask: 0,0,1000,0,1000,200,0,200

# Optional: Motion configuration
# NOTE: Can be overridden at the camera level
motion:
  # Optional: The threshold passed to cv2.threshold to determine if a pixel is different enough to be counted as motion. (default: shown below)
  # Increasing this value will make motion detection less sensitive and decreasing it will make motion detection more sensitive.
  # The value should be between 1 and 255.
  threshold: 25
  # Optional: Minimum size in pixels in the resized motion image that counts as motion (default: 30)
  # Increasing this value will prevent smaller areas of motion from being detected. Decreasing will
  # make motion detection more sensitive to smaller moving objects.
  # As a rule of thumb:
  #  - 15 - high sensitivity
  #  - 30 - medium sensitivity
  #  - 50 - low sensitivity
  contour_area: 30
  # Optional: Alpha value passed to cv2.accumulateWeighted when averaging the motion delta across multiple frames (default: shown below)
  # Higher values mean the current frame impacts the delta a lot, and a single raindrop may register as motion.
  # Too low and a fast moving person wont be detected as motion.
  delta_alpha: 0.2
  # Optional: Alpha value passed to cv2.accumulateWeighted when averaging frames to determine the background (default: shown below)
  # Higher values mean the current frame impacts the average a lot, and a new object will be averaged into the background faster.
  # Low values will cause things like moving shadows to be detected as motion for longer.
  # https://www.geeksforgeeks.org/background-subtraction-in-an-image-using-concept-of-running-average/
  frame_alpha: 0.2
  # Optional: Height of the resized motion frame  (default: 50)
  # This operates as an efficient blur alternative. Higher values will result in more granular motion detection at the expense
  # of higher CPU usage. Lower values result in less CPU, but small changes may not register as motion.
  frame_height: 50
  # Optional: motion mask
  # NOTE: see docs for more detailed info on creating masks
#  mask: 0,900,1080,900,1080,1920,0,1920
  # Optional: improve contrast (default: shown below)
  # Enables dynamic contrast improvement. This should help improve night detections at the cost of making motion detection more sensitive
  # for daytime.
  improve_contrast: False
  # Optional: Delay when updating camera motion through MQTT from ON -> OFF (default: shown below).
  mqtt_off_delay: 30

# Optional: Record configuration
# NOTE: Can be overridden at the camera level
record:
  # Optional: Enable recording (default: shown below)
  # WARNING: If recording is disabled in the config, turning it on via
  #          the UI or MQTT later will have no effect.
  # WARNING: Frigate does not currently support limiting recordings based
  #          on available disk space automatically. If using recordings,
  #          you must specify retention settings for a number of days that
  #          will fit within the available disk space of your drive or Frigate
  #          will crash.
  enabled: True
  # Optional: Number of minutes to wait between cleanup runs (default: shown below)
  # This can be used to reduce the frequency of deleting recording segments from disk if you want to minimize i/o
  expire_interval: 60
  # Optional: Retention settings for recording
  retain:
    # Optional: Number of days to retain recordings regardless of events (default: shown below)
    # NOTE: This should be set to 0 and retention should be defined in events section below
    #       if you only want to retain recordings of events.
    days: 0
    # Optional: Mode for retention. Available options are: all, motion, and active_objects
    #   all - save all recording segments regardless of activity
    #   motion - save all recordings segments with any detected motion
    #   active_objects - save all recording segments with active/moving objects
    # NOTE: this mode only applies when the days setting above is greater than 0
    mode: all
  # Optional: Event recording settings
  events:
    # Optional: Number of seconds before the event to include (default: shown below)
    pre_capture: 5
    # Optional: Number of seconds after the event to include (default: shown below)
    post_capture: 5
    # Optional: Objects to save recordings for. (default: all tracked objects)
    objects:
      - person
      - face
    # Optional: Restrict recordings to objects that entered any of the listed zones (default: no required zones)
    required_zones: []
    # Optional: Retention settings for recordings of events
    retain:
      # Required: Default retention days (default: shown below)
      default: 10
      # Optional: Mode for retention. (default: shown below)
      #   all - save all recording segments for events regardless of activity
      #   motion - save all recordings segments for events with any detected motion
      #   active_objects - save all recording segments for event with active/moving objects
      #
      # NOTE: If the retain mode for the camera is more restrictive than the mode configured
      #       here, the segments will already be gone by the time this mode is applied.
      #       For example, if the camera retain mode is "motion", the segments without motion are
      #       never stored, so setting the mode to "all" here won't bring them back.
      mode: motion
      # Optional: Per object retention days
      objects:
        person: 15
        face: 15

# Optional: Configuration for the jpg snapshots written to the clips directory for each event
# NOTE: Can be overridden at the camera level
snapshots:
  # Optional: Enable writing jpg snapshot to /media/frigate/clips (default: shown below)
  # This value can be set via MQTT and will be updated in startup based on retained value
  enabled: True
  # Optional: save a clean PNG copy of the snapshot image (default: shown below)
  clean_copy: True
  # Optional: print a timestamp on the snapshots (default: shown below)
  timestamp: False
  # Optional: draw bounding box on the snapshots (default: shown below)
  bounding_box: False
  # Optional: crop the snapshot (default: shown below)
  crop: True
  # Optional: height to resize the snapshot to (default: original size)
  #height: 175
  # Optional: Restrict snapshots to objects that entered any of the listed zones (default: no required zones)
  required_zones: []
  # Optional: Camera override for retention settings (default: global values)
  retain:
    # Required: Default retention days (default: shown below)
    default: 10
    # Optional: Per object retention days
    objects:
      person: 15
      face: 15

# Optional: RTMP configuration
# NOTE: Can be overridden at the camera level
rtmp:
  # Optional: Enable the RTMP stream (default: True)
  enabled: False

# Optional: Live stream configuration for WebUI
# NOTE: Can be overridden at the camera level
live:
  # Optional: Set the height of the live stream. (default: 720)
  # This must be less than or equal to the height of the detect stream. Lower resolutions
  # reduce bandwidth required for viewing the live stream. Width is computed to match known aspect ratio.
  height: 720
  # Optional: Set the encode quality of the live stream (default: shown below)
  # 1 is the highest quality, and 31 is the lowest. Lower quality feeds utilize less CPU resources.
  quality: 8

# Required
cameras:
  # Required: name of the camera
  # camera1:
  #   # Required: ffmpeg settings for the camera
  #   ffmpeg:
  #     hwaccel_args: []
        
  #     # Required: A list of input streams for the camera. See documentation for more information.
  #     inputs:
  #       - path: rtsp://admin:qwrtqwrt@10.106.54.131:8556/camera1
  #         roles:
  #           - detect

  #       - path: rtsp://admin:qwrtqwrt@10.106.54.131:8556/camera1
  #         roles:
  #           - record

  #   # Optional: timeout for highest scoring image before allowing it
  #   # to be replaced by a newer image. (default: shown below)
  #   best_image_timeout: 60

  #   ui:
  #     # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
  #     # By default the cameras are sorted alphabetically.
  #     order: 1
  #     # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
  #     dashboard: True

  camera161:
    # Required: ffmpeg settings for the camera
    ffmpeg:
      
      # Required: A list of input streams for the camera. See documentation for more information.
      inputs:
        #- path: rtsp://myusername:mypassword@172.17.0.253:45561/camera
        - path: rtsp://admin:qwrtqwrt@10.106.54.131:8556/camera161
          roles:
            - detect
            - record

    objects:
      # Optional: list of objects to track from labelmap.txt (default: shown below)
      track:
        - face

    detect:
      width: 2048 #2048
      height: 1538 #1538
      fps: 10
      enabled: False

    # Optional: timeout for highest scoring image before allowing it
    # to be replaced by a newer image. (default: shown below)
    best_image_timeout: 60

    ui:
      # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
      # By default the cameras are sorted alphabetically.
      order: 1
      # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
      dashboard: True

  camera166:
    # Required: ffmpeg settings for the camera
    ffmpeg:
      
      # Required: A list of input streams for the camera. See documentation for more information.
      inputs:
        #- path: rtsp://myusername:mypassword@172.17.0.253:45566/camera
        - path: rtsp://admin:qwrtqwrt@10.106.54.131:8556/camera166
          roles:
            - detect
            - record

    objects:
      # Optional: list of objects to track from labelmap.txt (default: shown below)
      track:
        - face

    record:
      enabled: True

    detect:
      width: 1920 #1280
      height: 1080 #720
      fps: 10
      enabled: True

    # Optional: timeout for highest scoring image before allowing it
    # to be replaced by a newer image. (default: shown below)
    #best_image_timeout: 60

    ui:
      # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
      # By default the cameras are sorted alphabetically.
      order: 2
      # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
      dashboard: True

#   camera167:
#     # Required: ffmpeg settings for the camera
#     ffmpeg:
      
#       # Required: A list of input streams for the camera. See documentation for more information.
#       inputs:
# #        - path: rtsp://myusername:mypassword@172.17.0.253:45567/camera
#         - path: rtsp://admin:qwrtqwrt@10.106.54.131:8556/camera167
#           roles:
#             - detect
#             - record

#         #- path: rtsp://myusername:mypassword@172.17.0.253:9554/camera167
#         #- path: rtsp://root:qtsc@172.17.1.49:554/1/h264major
#         #  roles:
#         #    - record

#     objects:
#       # Optional: list of objects to track from labelmap.txt (default: shown below)
#       track:
#         - face

#     detect:
#       width: 854 #1280
#       height: 480 #720
#       fps: 5
#       enabled: True

#     # Optional: timeout for highest scoring image before allowing it
#     # to be replaced by a newer image. (default: shown below)
#     best_image_timeout: 60

#     ui:
#       # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
#       # By default the cameras are sorted alphabetically.
#       order: 3
#       # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
#       dashboard: True

  testcam1:
    ffmpeg:
      inputs:
        - path: /media/frigate/qtsc_clip.mp4
          input_args: -re -stream_loop -1 -fflags +genpts
          roles:
            - detect

    objects:
      # Optional: list of objects to track from labelmap.txt (default: shown below)
      track:
        - face

    detect:
      width: 1920 #1536 #1280
      height: 1080 #864 #720
      fps: 5
      enabled: True

    ui:
      # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
      # By default the cameras are sorted alphabetically.
      order: 4
      # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
      dashboard: True

  testcam2:
    ffmpeg:
      inputs:
        - path: /media/frigate/face-demographics-walking.mp4
          input_args: -re -stream_loop -1 -fflags +genpts
          roles:
            - detect
            - rtmp

    objects:
      # Optional: list of objects to track from labelmap.txt (default: shown below)
      track:
        - face

    detect:
      width: 1536 #1536 #1280
      height: 864 #864 #720
      fps: 4
      enabled: True

    ui:
      # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
      # By default the cameras are sorted alphabetically.
      order: 5
      # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
      dashboard: True

  # testcam3:
  #   ffmpeg:
  #     inputs:
  #       - path: /media/frigate/face-demographics-walking-and-pause.mp4
  #         input_args: -re -stream_loop -1 -fflags +genpts
  #         roles:
  #           - detect
  #           - rtmp

  #   objects:
  #     # Optional: list of objects to track from labelmap.txt (default: shown below)
  #     track:
  #       - person

  #   detect:
  #     width: 768 #1536 #1280
  #     height: 432 #864 #720
  #     fps: 10
  #     enabled: True

  #   ui:
  #     # Optional: Adjust sort order of cameras in the UI. Larger numbers come later (default: shown below)
  #     # By default the cameras are sorted alphabetically.
  #     order: 6
  #     # Optional: Whether or not to show the camera in the Frigate UI (default: shown below)
  #     dashboard: True
